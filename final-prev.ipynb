{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as patches\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected = True) \n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', 1000)\n",
    "from bokeh.models import Panel, Tabs\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "#import lightgbm as lgb\n",
    "import plotly.figure_factory as ff\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers \n",
    "from keras.layers import Reshape,Concatenate \n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "#from tensorboardcolab import *\n",
    "from tensorflow.keras.regularizers import l2  \n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Masking\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import gensim\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec \n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "import tokenization\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Masking\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import fasttext\n",
    "import os\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, MaxPooling2D\n",
    "import json\n",
    "import gc\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing import text, sequence \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.models import load_model\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.python.keras import backend\n",
    "import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 10 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# question_text and document_text are the inputs.\n",
    "# bool_long means boolean value which indicates whether the data is short or long q&a.\n",
    "max_seq_length=200\n",
    "def predict(doc_text,ques_text,bool_long):\n",
    "    max_seq_length=200\n",
    "    \n",
    "    dic={'document_text':doc_text,'question_text':ques_text}\n",
    "    columns1= ['document_text','question_text']\n",
    "    inputs_df= pd.DataFrame(dic,columns=columns1)\n",
    "\n",
    "    \n",
    "    \n",
    "## SHORT Q&A MODEL\n",
    "    if not bool_long:\n",
    "        bert_model = load_model(\"bertmodel\")\n",
    "        tokenizer = pickle.load(open(\"tokenizerf.pickel\",\"rb\")) \n",
    "\n",
    "# converting tokens to ID's\n",
    "        \n",
    "        \n",
    "        def TokenizeAndConvertToIds(text):\n",
    "            tokens= tokenizer.tokenize(text) # tokenize the reviews\n",
    "            tokens=tokens[0:(max_seq_length-2)] \n",
    "            tokens=['[CLS]',*tokens,'[SEP]'] # adding cls and sep at the end\n",
    "            masked_array=np.array([1]*len(tokens) + [0]* (max_seq_length-len(tokens))) # masking \n",
    "            segment_array=np.array([0]*max_seq_length) \n",
    "            if(len(tokens)<max_seq_length): \n",
    "                padding=['[PAD]']*(max_seq_length-len(tokens)) # padding\n",
    "                tokens=[*tokens,*padding] \n",
    "            tokentoid=np.array(tokenizer.convert_tokens_to_ids(tokens)) # converting the tokens to id\n",
    "            return tokentoid,masked_array,segment_array\n",
    "\n",
    "        dtext=inputs_df['document_text']\n",
    "        qtext=inputs_df['question_text']\n",
    "        \n",
    "        \n",
    "#token_to_id conversion of answer data      \n",
    "\n",
    "# dtext means document_text\n",
    "# qtext means question_text\n",
    "        from tqdm import tqdm \n",
    "        dtext_tokens=[]\n",
    "        dtext_mask=[]\n",
    "        dtext_segment=[]\n",
    "\n",
    "        for i in dtext: \n",
    "            tokentoid,masked_array,segment_array=TokenizeAndConvertToIds(i)\n",
    "            dtext_tokens.append(tokentoid)\n",
    "            dtext_mask.append(masked_array)\n",
    "            dtext_segment.append(segment_array)\n",
    "\n",
    "        dtext_tokens=np.asarray(dtext_tokens)\n",
    "        dtext_mask=np.asarray(dtext_mask) \n",
    "        dtext_segment=np.asarray(dtext_segment) \n",
    "        \n",
    "# X_train_pooled_output of answers      \n",
    "        dtext_pooled_output=bert_model.predict([dtext_tokens,dtext_mask,dtext_segment])     \n",
    "        \n",
    "\n",
    "        tokenizer=pickle.load(open(\"tokenizerlong2f.pickel\",\"rb\"))\n",
    "        \n",
    "# token_to_sequences conversion of question data       \n",
    "        \n",
    "        def compute_text_and_questions1(inputs_df,tokenizer): \n",
    "            question_tok = tokenizer.texts_to_sequences(inputs_df.question_text.values)\n",
    "            question_tok = sequence.pad_sequences(question_tok)\n",
    "            return question_tok\n",
    "\n",
    "        question_tok=compute_text_and_questions1(inputs_df,tokenizer)\n",
    "        \n",
    "# loading short model\n",
    "        \n",
    "        model1=load_model(\"shortmodelfinal\")\n",
    "        \n",
    "# Predicting the test data\n",
    "        dtext_temp=dtext_pooled_output.reshape(dtext_pooled_output.shape[0],dtext_pooled_output.shape[1],1) \n",
    "        predf1=model1.predict([question_tok,dtext_temp])    \n",
    "\n",
    "        \n",
    "        indf=[]\n",
    "        for i in range(len(predf1[0])): \n",
    "            arg_max=np.argmax(predf1[2][i])\n",
    "            indf.append(arg_max) \n",
    "            \n",
    "# Extracting YES,NO and NONE            \n",
    "        yesnolist=[]\n",
    "        for i in range(len(indf)):\n",
    "            if indf[i]==0:\n",
    "                yesnolist.append('NO')\n",
    "            elif indf[i]==1:\n",
    "                yesnolist.append('NONE')\n",
    "            elif indf[i]==2:\n",
    "                yesnolist.append('YES')\n",
    "\n",
    "# If NONE is the answer, then predict indices \n",
    "        l3=[]\n",
    "        if yesnolist[0]=='NONE':\n",
    "\n",
    "            for i in range(inputs_df.shape[0]):\n",
    "                j=''\n",
    "                print(\"Predicted Start index is: \",int(predf1[0][i][0]))\n",
    "                print(\"Predicted End index is: \",int(predf1[1][i][0]))        \n",
    "                print(\"Question is: \", inputs_df['question_text'].values[i])\n",
    "                for k in inputs_df['document_text'].values[i].split(' ')[int(predf1[0][i][0]):int(predf1[1][i][0])]:\n",
    "                    j=j+\" \"+k\n",
    "                print(\"Answer is: \",j)\n",
    "            print(\" \",end='\\n')\n",
    "        \n",
    "# YES or NO\n",
    "        else:\n",
    "            print(yesnolist[0])\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "## LONG Q&A MODEL                \n",
    "    else:\n",
    "        bert_model = load_model(\"bertmodel\")\n",
    "        tokenizer = pickle.load(open(\"tokenizerf.pickel\",\"rb\"))\n",
    "# converting tokens to ID's\n",
    "        \n",
    "        \n",
    "        def TokenizeAndConvertToIds(text):\n",
    "            tokens= tokenizer.tokenize(text) # tokenize the reviews\n",
    "            tokens=tokens[0:(max_seq_length-2)] \n",
    "            tokens=['[CLS]',*tokens,'[SEP]'] # adding cls and sep at the end\n",
    "            masked_array=np.array([1]*len(tokens) + [0]* (max_seq_length-len(tokens))) # masking \n",
    "            segment_array=np.array([0]*max_seq_length) \n",
    "            if(len(tokens)<max_seq_length): \n",
    "                padding=['[PAD]']*(max_seq_length-len(tokens)) # padding\n",
    "                tokens=[*tokens,*padding] \n",
    "            tokentoid=np.array(tokenizer.convert_tokens_to_ids(tokens)) # converting the tokens to id\n",
    "            return tokentoid,masked_array,segment_array\n",
    "\n",
    "        dtext=inputs_df['document_text']\n",
    "        qtext=inputs_df['question_text']\n",
    "        \n",
    "        \n",
    "#token_to_id conversion of answer data      \n",
    "\n",
    "# dtext means document_text\n",
    "        from tqdm import tqdm \n",
    "        dtext_tokens=[]\n",
    "        dtext_mask=[]\n",
    "        dtext_segment=[]\n",
    "\n",
    "        for i in dtext: \n",
    "            tokentoid,masked_array,segment_array=TokenizeAndConvertToIds(i)\n",
    "            dtext_tokens.append(tokentoid)\n",
    "            dtext_mask.append(masked_array)\n",
    "            dtext_segment.append(segment_array)\n",
    "\n",
    "        dtext_tokens=np.asarray(dtext_tokens)\n",
    "        dtext_mask=np.asarray(dtext_mask) \n",
    "        dtext_segment=np.asarray(dtext_segment) \n",
    "        \n",
    "# X_train_pooled_output of answers      \n",
    "        dtext_pooled_output=bert_model.predict([dtext_tokens,dtext_mask,dtext_segment])     \n",
    "        \n",
    "\n",
    "        tokenizer=pickle.load(open(\"tokenizerlong2f.pickel\",\"rb\"))\n",
    "        \n",
    "# token_to_sequences conversion of question data       \n",
    "        \n",
    "        def compute_text_and_questions1(inputs_df,tokenizer): \n",
    "            question_tok = tokenizer.texts_to_sequences(inputs_df.question_text.values)\n",
    "            question_tok = sequence.pad_sequences(question_tok)\n",
    "            return question_tok\n",
    "\n",
    "        question_tok=compute_text_and_questions1(inputs_df,tokenizer)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "# loading long model        \n",
    "        model1=load_model(\"longmodelfinal\")\n",
    "     \n",
    "        dtext_temp=dtext_pooled_output.reshape(dtext_pooled_output.shape[0],dtext_pooled_output.shape[1],1) \n",
    "#predicting the test data      \n",
    "        predf1=model1.predict([question_tok,dtext_temp])    \n",
    "      \n",
    "        print(' ',end='\\n')\n",
    "\n",
    "# questions and answers in the range of predicted indices\n",
    "        j=''\n",
    "        for i in range(inputs_df.shape[0]):\n",
    "            j=''\n",
    "            print(\"Predicted Start index is: \",int(predf1[0][i])) \n",
    "            print(\"Predicted End index is: \",int(predf1[1][i]))        \n",
    "            print(end='\\n')\n",
    "            print(\"Question is: \", inputs_df['question_text'].values[i])\n",
    "            for k in inputs_df['document_text'].values[i].split(' ')[int(predf1[0][i][0]):int(predf1[1][i][0])]:\n",
    "                j=j+\" \"+k\n",
    "            print(\"Answer is: \",j)\n",
    "            print(\" \",end='\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving input extracted from the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9caf5cfa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c5d590440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      " \n",
      "Predicted Start index is:  368\n",
      "Predicted End index is:  661\n",
      "\n",
      "Question is:  what is the musical term for fast tempo\n",
      "Answer is:   or farcical opera </Td> </Tr> <Tr> <Td> Cabaletta </Td> <Td> from copola ( couplet ) </Td> <Td> A two - part musical form </Td> </Tr> <Tr> <Td> Cadenza </Td> <Td> falling </Td> <Td> A florid solo at the end of a performance </Td> </Tr> <Tr> <Td> Cantata </Td> <Td> sung </Td> <Td> A piece for orchestra and singers </Td> </Tr> <Tr> <Td> Capriccio </Td> <Td> caprice </Td> <Td> A lively piece , free in form , often used to show musical skill </Td> </Tr> <Tr> <Td> Cavatina </Td> <Td> small instrumental tone </Td> <Td> A simple melody or song </Td> </Tr> <Tr> <Td> Coda </Td> <Td> tail </Td> <Td> The end of a piece </Td> </Tr> <Tr> <Td> Concerto </Td> <Td> concert </Td> <Td> A work for one or more solo instruments accompanied by an orchestra </Td> </Tr> <Tr> <Td> Concertino </Td> <Td> little concert </Td> <Td> A short concerto ; the solo instrument in a concerto </Td> </Tr> <Tr> <Td> Concerto grosso </Td> <Td> big concert </Td> <Td> A Baroque form of concerto , with a group of solo instruments </Td> </Tr> <Tr> <Td> Da capo aria </Td> <Td> from the head aria </Td> <Td> A three - section musical form </Td> </Tr> <Tr> <Td> Dramma giocoso </Td> <Td> jocular drama </Td> <Td> A form of opera </Td> </Tr> <Tr> <Td> Dramma per musica </Td> <Td> drama for music </Td> <Td> Libretto </Td> </Tr> <Tr> <Td> Fantasia </Td> <Td> fantasy </Td> <Td> A musical composition or `` idea '' typified by improvisation </Td> </Tr> <Tr> <Td> Farsa </Td> <Td> farce </Td> <Td> A one - act comical opera </Td> </Tr> <Tr> <Td> festa teatrale </Td> <Td> theatrical party </Td> <Td> A genre of opera </Td> </Tr> <Tr> <Td> Fioritura </Td> <Td> flowery\n",
      " \n",
      "CPU times: user 26.3 s, sys: 2.14 s, total: 28.4 s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#long answer\n",
    "predict(doc_text,ques_text,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c536eab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9c49f05a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Predicted Start index is:  652\n",
      "Predicted End index is:  665\n",
      "Question is:  what is the musical term for fast tempo\n",
      "Answer is:   opera </Td> </Tr> <Tr> <Td> Fioritura </Td> <Td> flowery </Td> <Td> A highly\n",
      " \n",
      "CPU times: user 26.4 s, sys: 1.41 s, total: 27.8 s\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#short answer\n",
    "predict(doc_text,ques_text,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing input from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, sample = True, chunksize = 50000): \n",
    "    if sample == True:\n",
    "        df = [] \n",
    "        with open(path, 'rt') as reader:\n",
    "            for i in range(chunksize):\n",
    "                df.append(json.loads(reader.readline()))\n",
    "        df = pd.DataFrame(df)\n",
    "        print('Our sampled dataset have {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "    else:\n",
    "        df = pd.read_json(path, orient = 'records', lines = True)\n",
    "        print('Our dataset have {} rows and {} columns'.format(df.shape[0], df.shape[1]))\n",
    "        gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our sampled dataset have 50000 rows and 6 columns\n"
     ]
    }
   ],
   "source": [
    "train1 = read_data('simplified-nq-train.jsonl', sample = True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_text</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email marketing - Wikipedia &lt;H1&gt; Email marketi...</td>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Mother ( How I Met Your Mother ) - wikiped...</td>\n",
       "      <td>how i.met your mother who is the mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human fertilization - wikipedia &lt;H1&gt; Human fer...</td>\n",
       "      <td>what type of fertilisation takes place in humans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>List of National Football League career quarte...</td>\n",
       "      <td>who had the most wins in the nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roanoke Colony - wikipedia &lt;H1&gt; Roanoke Colony...</td>\n",
       "      <td>what happened to the lost settlement of roanoke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       document_text  \\\n",
       "0  Email marketing - Wikipedia <H1> Email marketi...   \n",
       "1  The Mother ( How I Met Your Mother ) - wikiped...   \n",
       "2  Human fertilization - wikipedia <H1> Human fer...   \n",
       "3  List of National Football League career quarte...   \n",
       "4  Roanoke Colony - wikipedia <H1> Roanoke Colony...   \n",
       "\n",
       "                                       question_text  \n",
       "0  which is the most common use of opt-in e-mail ...  \n",
       "1            how i.met your mother who is the mother  \n",
       "2   what type of fertilisation takes place in humans  \n",
       "3                   who had the most wins in the nfl  \n",
       "4    what happened to the lost settlement of roanoke  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te=pd.DataFrame(train1,columns=['document_text','question_text'])\n",
    "te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "te=te.iloc[35] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document_text    List of Italian musical terms used in English ...\n",
       "question_text              what is the musical term for fast tempo\n",
       "Name: 35, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc_text=[te['document_text']]\n",
    "ques_text=[te['question_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text=[]\n",
    "for i in te['document_text'].values:\n",
    "    doc_text.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques_text=[]\n",
    "for i in te['question_text'].values:\n",
    "    ques_text.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
